{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist RAG?\n",
    "\n",
    "##### 1. **Retrieve**: Finde die relevantesten Dokumente zur Beantwortung der Frage.\n",
    "##### 2. **Augment**: Gib die relevanten Dokumente zusammen mit der Frage an das LLM weiter.\n",
    "##### 3. **Generate**: Das LLM generiert eine Antwort *basierend* auf den retrievted Dokumenten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "# Imports & keys \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "os.chdir(\"/workspace\")\n",
    "\n",
    "# initialize API keys\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"API Keys retrieved successfully\")\n",
    "else:\n",
    "    print(\"API Keys not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist ein *embedding*?\n",
    "\n",
    "### Worte werden in Zahlen umgewandelt\n",
    "\n",
    "- Das **Embedding Modell** konvertiert einen Begriff oder einen Satz in eine Liste von Zahlen (-> VeKtor).  \n",
    "- Vektoren (von Begriffen oder Sätzen) die in eine *ähnliche* Richtung zeigen, repräsentieren Begriffe mit einer *ähnlichen* semantischen Bedeutung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a small embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# examples of sentences with different semantic meanings\n",
    "# sentences = [\n",
    "#     \"Es regnet draußen\",                    \n",
    "#     \"Ich brauche einen Regenschirm\",        \n",
    "#     \"Die Hauptstadt von Frankreich ist Paris\",\n",
    "# ]\n",
    "sentences = [\n",
    "    \"Hund\",                    \n",
    "    \"Wolf\",        \n",
    "    \"Regenschirm\",\n",
    "]\n",
    "\n",
    "# embed the sentences using the same embedding model\n",
    "embeddings = [embedding_model.embed_query(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the sentence: Hund\n",
      "These are the first 5 numbers of the vector: [-0.040633514523506165, -0.04273275285959244, 0.002069076057523489, 0.015406472608447075, 0.01820545643568039] ...\n",
      "The corresponding vector has a length of: 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# this is how an embedding looks like\n",
    "print(f\"This is the sentence:\", sentences[0])\n",
    "print(\"These are the first 5 numbers of the vector:\", embeddings[0][:5], \"...\")\n",
    "print(f\"The corresponding vector has a length of: {len(embeddings[0])} dimensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantische Ähnlichkeit zwischen folgenden Sätzen:\n",
      "\"Hund\" vs. \"Wolf:  0.385\n",
      "\"Hund\" vs. \"Regenschirm\":  0.289\n",
      "\"Wolf\" vs. \"Regenschirm\":  0.154\n"
     ]
    }
   ],
   "source": [
    "# calculate semantic proximity using cosine_similarity\n",
    "sim_matrix = cosine_similarity(np.array(embeddings))\n",
    "\n",
    "# print relationshop between the sentences\n",
    "print(\"Semantische Ähnlichkeit zwischen folgenden Sätzen:\")\n",
    "# labels = [\n",
    "#     '\"Es regnet draußen\" vs. \"Ich brauche einen Regenschirm\"', \n",
    "#     '\"Es regnet draußen\" vs. \"Die Hauptstadt von Frankreich ist Paris\"',\n",
    "#     '\"Ich brauche einen Regenschirm\" vs. \"Die Hauptstadt von Frankreich ist Paris\"'\n",
    "# ]\n",
    "labels = [\n",
    "    '\"Hund\" vs. \"Wolf', \n",
    "    '\"Hund\" vs. \"Regenschirm\"',\n",
    "    '\"Wolf\" vs. \"Regenschirm\"'\n",
    "]\n",
    "    \n",
    "scores = [\n",
    "    sim_matrix[0, 1],\n",
    "    sim_matrix[0, 2],\n",
    "    sim_matrix[1, 2],\n",
    "]\n",
    "for lbl, sc in zip(labels, scores):\n",
    "    print(f\"{lbl:<6}: {sc: .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist ein *Vector Store*?\n",
    "\n",
    "- Ein einzelnes Embedding ist nur eine Zahlentabelle. Erst wenn wir **tausende** davon nebeneinander speichern, können wir nach “welche klingen am ähnlichsten?” fragen.  \n",
    "- Der Vektorstore speichert jeden Vektor samt Metadaten (Titel, URL, Abschnitt) **und** baut einen Index für schneller Ähnlichkeitssuche (≈ Millisekunden).  \n",
    "- Ohne diesen Index müssten wir bei jeder Frage alle Vektoren einzeln vergleichen – bei > 5000 Artikeln wäre das Minuten statt Millisekunden.  \n",
    "- Der Vector Store ist die **semantische Stichwortkartei** – er liefert die x passendsten Text‑Schnipsel, die wir anschließend im 1. Schritt RAG‑Prozesses **retrieven**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'10_Copernicus-Report_ 2024 war 1_6 Grad wärmer als vo.txt'\n",
      "'07_Dunkelflauten_ Wie hohe Strompreise gesenkt werden.txt'\n",
      "'40_FDA lässt neuartiges Medikament zur Behandlung von.txt'\n",
      "'33_KI-Modell analysiert und generiert DNA-Strukturen.txt'\n",
      "'16_KI senkt Zustimmung zu Verschwörungstheorien.txt'\n"
     ]
    }
   ],
   "source": [
    "# show the content of the data path\n",
    "data_path=\"data/example_data\"\n",
    "\n",
    "for datei in os.listdir(data_path):\n",
    "    if datei.endswith(\".txt\"):\n",
    "        print(repr(datei))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore successfully created and saved to data/vectorstores\n"
     ]
    }
   ],
   "source": [
    "# build the vectorstore \n",
    "\n",
    "# --- set parameters ---\n",
    "data_path = \"data/example_data\"  # data input folder\n",
    "text_chunk_size = 512  # chunk size\n",
    "text_chunk_overlap = 20  # chunk overlap\n",
    "embedding_model = \"text-embedding-3-small\"  # embedding model\n",
    "save_path = \"data/vectorstores\"  # directory to save the vector store\n",
    "\n",
    "\"\"\"\n",
    "Creates a vectorstore for both tables and text documents.\n",
    "\n",
    "Parameters:\n",
    "    data_table(str): path to folder containing txt files\n",
    "    text_chunk_size (int): Chunk size for text documents. Default is 512.\n",
    "    text_chunk_overlap (int): Overlap for text documents. Default is 20.\n",
    "    embedding_model (str): Embedding model to use. Default is \"text-embedding-3-small\".\n",
    "    db_backend (str): Vector store backend. Default is \"faiss\".\n",
    "    save_path (str): Directory to save the vector store. Defaults to \"vectorstores\".\n",
    "\n",
    "Returns:\n",
    "    vectorstore: The created vector store.\n",
    "\"\"\"\n",
    "\n",
    "# ensure save directory exists\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Read all txt files and create documents\n",
    "documents = []\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Split and get title\n",
    "        lines = content.split('\\n')\n",
    "        title = lines[0].replace('TITLE: ', '').strip()\n",
    "\n",
    "        # Get text content excluding title and empty line\n",
    "        text_content = '\\n'.join(lines[2:])\n",
    "\n",
    "        # Create document with metadata\n",
    "        doc = Document(\n",
    "            page_content=text_content,\n",
    "            metadata={'title': title}\n",
    "        )\n",
    "        documents.append(doc)\n",
    "\n",
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=text_chunk_size,\n",
    "    chunk_overlap=text_chunk_overlap\n",
    ")\n",
    "\n",
    "# Split text documents into overlapping chunks\n",
    "split_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(model=embedding_model)\n",
    "\n",
    "# Build FAISS vectorstore and save to disk\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=split_documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "#vectorstore.save_local(save_path)\n",
    "\n",
    "print(f\"Vectorstore successfully created and saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Title: FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu\n",
      "Content:\n",
      "„Obwohl die Schizophrenie eine der sozioökonomisch teuersten Erkrankung mit einer Lebenszeitreduktion von mehr als 15 Jahren und einer massiven Einschränkung der Lebensqualität ist, findet leider nur wenig innovative Arzneiforschung statt. Erfreulicherweise ändert sich das im Moment. Andere vielversprechende Medikamente sind auf jeden Fall Emraclidin, welches als positiv allosterischer Modulator a...\n",
      "\n",
      "--- Result 2 ---\n",
      "Title: FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu\n",
      "Content:\n",
      "„Zudem ist es prinzipiell gut, wenn Behandelnde aus einem breiten Spektrum an guten Medikamenten zur Behandlung der Patienten wählen können. Je nach Person und Krankheitsbild können unterschiedliche Medikamente besser passen. Dies ist seit einigen Jahrzehnten der erste neue Ansatz für ein Schizophrenie-Medikament mit einer offenbar guten Wirksamkeit und anderen Nebenwirkungen. Ob KarXT die bisheri...\n",
      "\n",
      "--- Result 3 ---\n",
      "Title: FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu\n",
      "Content:\n",
      "Studien. Ein weiteres Medikament zur Behandlung von Schizophrenie, das ebenfalls vielversprechend aussieht, ist Emraclidine, welches auch auf dem muskarinergen Wirkmechanismus basiert.“...\n"
     ]
    }
   ],
   "source": [
    "# quick sanity check (retrieve relevant documents for a search query)\n",
    "search_query = \"Welche Medikamente werden gegen Schizophrenie eingesetzt?\"\n",
    "results = vectorstore.similarity_search(query=search_query, k=3)\n",
    "\n",
    "# pretty print\n",
    "for i, doc in enumerate(results, start=1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(f\"Title: {doc.metadata.get('title')}\")\n",
    "    print(f\"Content:\\n{doc.page_content[:400]}...\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
