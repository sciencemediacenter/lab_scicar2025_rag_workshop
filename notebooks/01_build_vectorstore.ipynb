{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist RAG?\n",
    "\n",
    "##### 1. **Retrieve**: Finde die relevantesten Dokumente zur Beantwortung der Frage.\n",
    "##### 2. **Augment**: Gib die relevanten Dokumente zusammen mit der Frage an das LLM weiter.\n",
    "##### 3. **Generate**: Das LLM generiert eine Antwort *basierend* auf den retrievted Dokumenten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & keys \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "os.chdir(\"/workspace\")\n",
    "\n",
    "# initialize API keys\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"API Keys retrieved successfully\")\n",
    "else:\n",
    "    print(\"API Keys not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist ein *embedding*?\n",
    "\n",
    "### Worte werden in Zahlen umgewandelt\n",
    "\n",
    "- Das **Embedding Modell** konvertiert einen Begriff oder einen Satz in eine Liste von Zahlen (-> VeKtor).  \n",
    "- Vektoren (von Begriffen oder Sätzen) die in eine *ähnliche* Richtung zeigen, repräsentieren Begriffe mit einer *ähnlichen* semantischen Bedeutung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a small embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# examples of sentences with different semantic meanings\n",
    "sentences = [\n",
    "    \"Es regnet draußen\",                    \n",
    "    \"Ich brauche einen Regenschirm\",        \n",
    "    \"Die Hauptstadt von Frankreich ist Paris\",\n",
    "]\n",
    "\n",
    "# embed the sentences using the same embedding model\n",
    "embeddings = [embedding_model.embed_query(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the sentence: Es regnet draußen\n",
      "These are the first 5 numbers of the vector: [-0.010474217124283314, 0.0052315667271614075, 0.019840052351355553, 0.019840052351355553, 0.006927392445504665] ...\n",
      "The corresponding vector has a length of: 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# this is how an embedding looks like\n",
    "print(f\"This is the sentence:\", sentences[0])\n",
    "print(\"These are the first 5 numbers of the vector:\", embeddings[0][:5], \"...\")\n",
    "print(f\"The corresponding vector has a length of: {len(embeddings[0])} dimensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantische Ähnlichkeit zwischen folgenden Sätzen:\n",
      "\"Es regnet draußen\" vs. \"Ich brauche einen Regenschirm\":  0.440\n",
      "\"Es regnet draußen\" vs. \"Die Hauptstadt von Frankreich ist Paris\":  0.124\n",
      "\"Ich brauche einen Regenschirm\" vs. \"Die Hauptstadt von Frankreich ist Paris\":  0.139\n",
      "\"Die Hauptstadt von Frankreich ist Paris\" vs. \"Der Eiffelturm ist ein 330 Meter hoher Eisenfachwerkturm\" :  0.271\n"
     ]
    }
   ],
   "source": [
    "# calculate semantic proximity using cosine_similarity\n",
    "sim_matrix = cosine_similarity(np.array(embeddings))\n",
    "\n",
    "# print relationshop between the sentences\n",
    "print(\"Semantische Ähnlichkeit zwischen folgenden Sätzen:\")\n",
    "labels = [\n",
    "    '\"Es regnet draußen\" vs. \"Ich brauche einen Regenschirm\"', \n",
    "    '\"Es regnet draußen\" vs. \"Die Hauptstadt von Frankreich ist Paris\"',\n",
    "    '\"Ich brauche einen Regenschirm\" vs. \"Die Hauptstadt von Frankreich ist Paris\"']\n",
    "    \n",
    "scores = [\n",
    "    sim_matrix[0, 1],\n",
    "    sim_matrix[0, 2],\n",
    "    sim_matrix[1, 2],\n",
    "]\n",
    "for lbl, sc in zip(labels, scores):\n",
    "    print(f\"{lbl:<6}: {sc: .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist ein *Vector Store*?\n",
    "\n",
    "- Ein einzelnes Embedding ist nur eine Zahlentabelle. Erst wenn wir **tausende** davon nebeneinander speichern, können wir nach “welche klingen am ähnlichsten?” fragen.  \n",
    "- Der Vektorstore speichert jeden Vektor samt Metadaten (Titel, URL, Abschnitt) **und** baut einen Index für schneller Ähnlichkeitssuche (≈ Millisekunden).  \n",
    "- Ohne diesen Index müssten wir bei jeder Frage alle Vektoren einzeln vergleichen – bei > 5000 Artikeln wäre das Minuten statt Millisekunden.  \n",
    "- Der Vector Store ist die **semantische Stichwortkartei** – er liefert die x passendsten Text‑Schnipsel, die wir anschließend im 1. Schritt RAG‑Prozesses **retrieven**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vectorstore\n",
    "def create_vectorstore(\n",
    "    data_path: str, # data input folder\n",
    "    text_chunk_size: int = 512,  # chunk size \n",
    "    text_chunk_overlap: int = 20,  # chunk overlap \n",
    "    embedding_model: str = \"text-embedding-3-small\",  # embedding model\n",
    "    save_path: str = \"data/vectorstores\",  # directory to save the vector store\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a vectorstore for both tables and text documents.\n",
    "\n",
    "    Parameters:\n",
    "        data_table(str): path to folder containing txt files\n",
    "        text_chunk_size (int): Chunk size for text documents. Default is 512.\n",
    "        text_chunk_overlap (int): Overlap for text documents. Default is 20.\n",
    "        embedding_model (str): Embedding model to use. Default is \"text-embedding-3-small\".\n",
    "        db_backend (str): Vector store backend. Default is \"faiss\".\n",
    "        save_path (str): Directory to save the vector store. Defaults to \"vectorstores\".\n",
    "\n",
    "    Returns:\n",
    "        vectorstore: The created vector store.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Read all txt files and create documents\n",
    "    documents = []\n",
    "    for filename in os.listdir(data_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(data_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Split into title and content\n",
    "            lines = content.split('\\n')\n",
    "            title = lines[0].replace('TITLE: ', '').strip()\n",
    "            # Skip title and separator line\n",
    "            text_content = '\\n'.join(lines[2:])\n",
    "            \n",
    "            # Create document with metadata\n",
    "            doc = Document(\n",
    "                page_content=text_content,\n",
    "                metadata={'title': title}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "    # Create text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=text_chunk_size,\n",
    "        chunk_overlap=text_chunk_overlap\n",
    "    )\n",
    "    \n",
    "    # Split text documents into overlapping chunks\n",
    "    split_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Create embeddings\n",
    "    embeddings = OpenAIEmbeddings(model=embedding_model)\n",
    "    \n",
    "    # Build FAISS vectorstore and save to disk\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=split_documents, \n",
    "        embedding=embeddings\n",
    "    )\n",
    "    vectorstore.save_local(save_path)\n",
    "\n",
    "    print(f\"Vectorstore successfully created and saved to {save_path}\")\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore successfully created and saved to data/vectorstores\n"
     ]
    }
   ],
   "source": [
    "vs = create_vectorstore(data_path=\"data/example_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3cab0201-0ca6-43ee-931b-94de1be567d1', metadata={'title': 'FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu'}, page_content='„Obwohl die Schizophrenie eine der sozioökonomisch teuersten Erkrankung mit einer Lebenszeitreduktion von mehr als 15 Jahren und einer massiven Einschränkung der Lebensqualität ist, findet leider nur wenig innovative Arzneiforschung statt. Erfreulicherweise ändert sich das im Moment. Andere vielversprechende Medikamente sind auf jeden Fall Emraclidin, welches als positiv allosterischer Modulator am M4-Rezeptor wirkt und einen vergleichbaren Ansatz wie KarXT aufweist. Hier hat die Firma AbbVie die'),\n",
       " Document(id='a452a6ef-ebd0-4b60-a60d-4503b0d6d10e', metadata={'title': 'FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu'}, page_content='„Zudem ist es prinzipiell gut, wenn Behandelnde aus einem breiten Spektrum an guten Medikamenten zur Behandlung der Patienten wählen können. Je nach Person und Krankheitsbild können unterschiedliche Medikamente besser passen. Dies ist seit einigen Jahrzehnten der erste neue Ansatz für ein Schizophrenie-Medikament mit einer offenbar guten Wirksamkeit und anderen Nebenwirkungen. Ob KarXT die bisherigen Medikamente ablösen könnte, wissen wir noch nicht, dafür braucht es die entsprechenden Studien. Ein'),\n",
       " Document(id='279a41bf-532a-45b7-85e6-9453cbf59035', metadata={'title': 'FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu'}, page_content='Studien. Ein weiteres Medikament zur Behandlung von Schizophrenie, das ebenfalls vielversprechend aussieht, ist Emraclidine, welches auch auf dem muskarinergen Wirkmechanismus basiert.“'),\n",
       " Document(id='db09f2c5-9266-4207-bdce-c659e0f4d2d9', metadata={'title': 'FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu'}, page_content='„Das Medikament KarXT ist meiner Einschätzung nach eine Möglichkeit, die Therapie von Psychosen und Schizophrenie für wenigstens einige Patient:innen zu revolutionieren. Das liegt an dem besonderen Wirkmechanismus von Xanomelin, einem M1/M4 muscarinergen Agonisten, der mit Trospium, einem peripher beschränkten Anticholiergikum kombiniert ist und über die Wirkung auf Muskarinrezeptoren indirekt die präsynaptische Dopaminausschüttung reduziert. Bisherige Antipsychotika blockieren postsynaptische'),\n",
       " Document(id='6d38fd9a-d9b2-44f7-b1a4-f0ab593efdc7', metadata={'title': 'FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu'}, page_content='Die amerikanische Arzneimittelbehörde FDA hat in der Nacht vom 26.09.2024 auf den 27.09.2024 das neuartige Medikament KarXT (Markenname Cobenfy) zur Behandlung von Schizophrenie zugelassen https://www.fda.gov/news-events/press-announcements/fda-approves-drug-new-mechanism-action-treatment-schizophrenia[I]. Die bisherigen Antipsychotika zielen mit ihrer Wirkung direkt auf den Botenstoff Dopamin ab, der im Körper etwa für das Belohnungssystem oder auch Bewegung, zuständig ist. Nebenwirkungen sind')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick sanity check (retrieve the corresponding documents for a search query)\n",
    "search_query = \"Welche Medikamente werden gegen Schizophrenie eingesetzt?\"\n",
    "vs.similarity_search(query=search_query, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
