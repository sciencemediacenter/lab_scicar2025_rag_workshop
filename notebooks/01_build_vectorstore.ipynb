{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "# Imports & keys \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "os.chdir(\"/workspace\")\n",
    "\n",
    "# initialize API keys\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"API Keys retrieved successfully\")\n",
    "else:\n",
    "    print(\"API Keys not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist ein *embedding*?\n",
    "\n",
    "### Worte werden in Zahlen umgewandelt\n",
    "\n",
    "- Das **Embedding Modell** konvertiert ein Wort, einen Satz, oder einen Textabschnitt in eine Liste von Zahlen (-> Vektor).  \n",
    "- Vektoren die in eine *ähnliche* Richtung zeigen, repräsentieren eine *ähnlichen* semantischen Bedeutung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a small embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# examples of sentences with different semantic meanings\n",
    "sentences = [\n",
    "    \"Es regnet draußen\",                    \n",
    "    \"Ich brauche einen Regenschirm\",        \n",
    "    \"Die Hauptstadt von Frankreich ist Paris\",\n",
    "]\n",
    "\n",
    "# embed the sentences using the same embedding model\n",
    "embeddings = [embedding_model.embed_query(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the sentence: Es regnet draußen\n",
      "These are the first 5 numbers of the vector: [-0.010474217124283314, 0.0052315667271614075, 0.019840052351355553, 0.019840052351355553, 0.006927392445504665] ...\n",
      "The corresponding vector has a length of: 1536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# this is how an embedding looks like\n",
    "print(f\"This is the sentence:\", sentences[0])\n",
    "print(\"These are the first 5 numbers of the vector:\", embeddings[0][:5], \"...\")\n",
    "print(f\"The corresponding vector has a length of: {len(embeddings[0])} dimensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantische Ähnlichkeit zwischen folgenden Sätzen:\n",
      "\"Es regnet draußen\" vs. \"Ich brauche einen Regenschirm\":  0.440\n",
      "\"Es regnet draußen\" vs. \"Die Hauptstadt von Frankreich ist Paris\":  0.124\n",
      "\"Ich brauche einen Regenschirm\" vs. \"Die Hauptstadt von Frankreich ist Paris\":  0.139\n"
     ]
    }
   ],
   "source": [
    "# calculate semantic proximity using cosine_similarity\n",
    "sim_matrix = cosine_similarity(np.array(embeddings))\n",
    "\n",
    "# print relationshop between the sentences\n",
    "print(\"Semantische Ähnlichkeit zwischen folgenden Sätzen:\")\n",
    "labels = [\n",
    "    '\"Es regnet draußen\" vs. \"Ich brauche einen Regenschirm\"', \n",
    "    '\"Es regnet draußen\" vs. \"Die Hauptstadt von Frankreich ist Paris\"',\n",
    "    '\"Ich brauche einen Regenschirm\" vs. \"Die Hauptstadt von Frankreich ist Paris\"']\n",
    "    \n",
    "scores = [\n",
    "    sim_matrix[0, 1],\n",
    "    sim_matrix[0, 2],\n",
    "    sim_matrix[1, 2],\n",
    "]\n",
    "for lbl, sc in zip(labels, scores):\n",
    "    print(f\"{lbl:<6}: {sc: .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was ist ein *Vector Store*?\n",
    "\n",
    "- Ein einzelnes Embedding ist nur eine Zahlentabelle. Erst wenn wir **tausende** davon nebeneinander speichern, können wir nach “welche sind am semantisch ähnlichsten?” fragen.  \n",
    "- Der Vektorstore speichert jeden Vektor samt Metadaten (Titel, URL, Abschnitt) **und** baut einen Index für schneller Ähnlichkeitssuche (≈ Millisekunden).  \n",
    "- Ohne diesen Index müssten wir bei jeder Frage alle Vektoren einzeln vergleichen - bei > 5000 Artikeln wäre das Minuten statt Millisekunden.  \n",
    "- Der Vector Store ist die **semantische Stichwortkartei** – er liefert die x passendsten Text‑Schnipsel, die wir anschließend im 1. Schritt RAG‑Prozesses **retrieven**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'10_Copernicus-Report_ 2024 war 1_6 Grad wärmer als vo.txt'\n",
      "'07_Dunkelflauten_ Wie hohe Strompreise gesenkt werden.txt'\n",
      "'40_FDA lässt neuartiges Medikament zur Behandlung von.txt'\n",
      "'33_KI-Modell analysiert und generiert DNA-Strukturen.txt'\n",
      "'16_KI senkt Zustimmung zu Verschwörungstheorien.txt'\n"
     ]
    }
   ],
   "source": [
    "# show the content of the data path\n",
    "data_path=\"data/example_data\"\n",
    "\n",
    "# our vectorstore consists of 5 text files\n",
    "for datei in os.listdir(data_path):\n",
    "    if datei.endswith(\".txt\"):\n",
    "        print(repr(datei))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore successfully created and saved to data/vectorstores\n"
     ]
    }
   ],
   "source": [
    "# build the vectorstore \n",
    "\n",
    "# set parameters for vectorstore creation\n",
    "data_path = \"data/example_data\"  # data input folder\n",
    "save_path = \"data/vectorstores\"  # directory to save the vector store\n",
    "embedding_model = \"text-embedding-3-small\"  # embedding model\n",
    "text_chunk_size = 512  # chunk size\n",
    "text_chunk_overlap = 20  # chunk overlap\n",
    "\n",
    "# ensure save directory exists\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Read all txt files and create documents for processing\n",
    "documents = []\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        # load each txt file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Split and extract the title\n",
    "        lines = content.split('\\n')\n",
    "        title = lines[0].replace('TITLE: ', '').strip()\n",
    "\n",
    "        # Get text content excluding title and empty line\n",
    "        text_content = '\\n'.join(lines[2:])\n",
    "\n",
    "        # Create document with metadata\n",
    "        doc = Document(\n",
    "            page_content=text_content,\n",
    "            metadata={'title': title}\n",
    "        )\n",
    "        documents.append(doc)\n",
    "\n",
    "# Create text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=text_chunk_size,\n",
    "    chunk_overlap=text_chunk_overlap\n",
    ")\n",
    "\n",
    "# Split text documents into overlapping chunks\n",
    "text_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(model=embedding_model)\n",
    "\n",
    "# Build FAISS vectorstore and save to disk\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "vectorstore.save_local(save_path)\n",
    "\n",
    "print(f\"Vectorstore successfully created and saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Title: FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu\n",
      "Doc ID: 8365664d-bedd-4ac9-833c-d6c6861f6b4d\n",
      "Text:\n",
      "„Obwohl die Schizophrenie eine der sozioökonomisch teuersten Erkrankung mit einer Lebenszeitreduktion von mehr als 15 Jahren und einer massiven Einschränkung der Lebensqualität ist, findet leider nur wenig innovative Arzneiforschung statt. Erfreulicherweise ändert sich das im Moment. Andere vielversprechende Medikamente sind auf jeden Fall Emraclidin, welches als positiv allosterischer Modulator a...\n",
      "\n",
      "--- Result 2 ---\n",
      "Title: FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu\n",
      "Doc ID: 379d36f1-da0e-4c06-8fee-a354f2b4b8c1\n",
      "Text:\n",
      "„Zudem ist es prinzipiell gut, wenn Behandelnde aus einem breiten Spektrum an guten Medikamenten zur Behandlung der Patienten wählen können. Je nach Person und Krankheitsbild können unterschiedliche Medikamente besser passen. Dies ist seit einigen Jahrzehnten der erste neue Ansatz für ein Schizophrenie-Medikament mit einer offenbar guten Wirksamkeit und anderen Nebenwirkungen. Ob KarXT die bisheri...\n",
      "\n",
      "--- Result 3 ---\n",
      "Title: FDA lässt neuartiges Medikament zur Behandlung von Schizophrenie zu\n",
      "Doc ID: b8875e5e-2d0e-49b4-8708-cf9b3691d2f5\n",
      "Text:\n",
      "Studien. Ein weiteres Medikament zur Behandlung von Schizophrenie, das ebenfalls vielversprechend aussieht, ist Emraclidine, welches auch auf dem muskarinergen Wirkmechanismus basiert.“...\n"
     ]
    }
   ],
   "source": [
    "# quick sanity check (retrieve relevant documents for a search query)\n",
    "search_query = \"Welche Medikamente werden gegen Schizophrenie eingesetzt?\"\n",
    "results = vectorstore.similarity_search(query=search_query, k=3)\n",
    "\n",
    "# pretty print\n",
    "for i, doc in enumerate(results, start=1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(f\"Title: {doc.metadata.get('title')}\")\n",
    "    print(f\"Doc ID: {doc.id}\")\n",
    "    print(f\"Text:\\n{doc.page_content[:400]}...\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
